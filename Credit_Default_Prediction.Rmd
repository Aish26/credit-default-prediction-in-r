---
title: "Credit_Default_Prediction"
author: "Aishwarya"
date: "2023-04-06"
output: html_document
---

**Loading required packages**
```{r}
library(glmnet)
library(caret)
library(psych)
library(pls)

```


**Data format pre-processing**
```{r}
train_default_data<-read.csv("loan_train_final.csv")
test_default_data<-read.csv("loan_test_final.csv")

#Employment column
train_default_data$employment<-as.integer(train_default_data$employment)
test_default_data$employment<-as.integer(test_default_data$employment)

#Train
sum(is.na(train_default_data$employment)) #333 NAs
length(train_default_data$employment) #Out of 600
mean_value=mean(train_default_data$employment,na.rm=TRUE)
train_default_data$employment <- ifelse(is.na(train_default_data$employment), mean_value, train_default_data$employment)

#Test
sum(is.na(test_default_data$employment)) #63 NAs
length(test_default_data$employment) #Out of 2400
mean_value=mean(test_default_data$employment,na.rm=TRUE)
test_default_data$employment <- ifelse(is.na(test_default_data$employment), mean_value, test_default_data$employment)

```



**Term column processing**
```{r}
train_default_data$term <- as.numeric(gsub("yrs", "", train_default_data$term))
test_default_data$term <- as.numeric(gsub("yrs", "", test_default_data$term))

# Check for missing values
sum(is.na(train_default_data))
sum(is.na(test_default_data))

```



```{r}
# Create a random sample of 80% of the data for training
library(rsample)
train_sample <- initial_split(train_default_data, prop = 0.8)
train_data <- training(train_sample)
test_data <- testing(train_sample)
```



```{r}

#EDA
plot(train_default_data$credit_ratio)
plot(train_default_data$interest)
plot(train_default_data$recover)
plot(train_default_data$coll_fee)
plot(train_default_data$out_prncp)
plot(train_default_data$total_cc)
plot(train_default_data$total_acc)
plot(train_default_data$amount)
plot(train_default_data$monthly_payment)
plot(train_default_data$funded)
plot(train_default_data$total_acc)
plot(train_default_data$term)

#Dataframe with all numerical variables
cor_data<-data.frame(train_default_data$credit_ratio,train_default_data$interest,train_default_data$recover,train_default_data$coll_fee,train_default_data$out_prncp,train_default_data$total_cc,train_default_data$total_acc,train_default_data$amount,train_default_data$monthly_payment,train_default_data$funded,train_default_data$total_acc,train_default_data$term)

pairs(cor_data, pch = 19)

#Correlation
cor(cor_data)

```


**Using logistic regression**
```{r}
suppressWarnings({default_log_model<-glm(default~.,data=train_data, family="binomial")
})
summary(default_log_model)
testProb <- predict(default_log_model, newdata = test_data, type = "response")
# Calculate the error on the test data taken out from train
testActual <- ifelse(testProb>0.5, 1, 0)
error <- sum(abs(testActual - test_data$default)) / nrow(test_data)
error

log_train_loss<-test_data$default*test_data$amount
testLoss <- testProb * test_data$amount

MAE<- sum(abs(log_train_loss-testLoss)) / nrow(test_data)
MAE
```


The model is predicting 6.67% incorrect predictions by keeping 0.5 as the threshold using logistic regression.
The mean absolute error for this training model is $2014

**Using logistic regression to predict using the actual test data **
```{r}
predicted_prob <- predict(default_log_model, newdata = test_default_data, type = "response")
log_predicted_loss=predicted_prob*test_default_data$amount

```


```{r}
log_test_loss<-test_default_data$default*test_default_data$amount

logit_MAE<- sum(abs(log_test_loss -log_predicted_loss)) / nrow(test_default_data)
logit_MAE
```
The mean absolute error for this training model is $1929


**Lasso regression**
```{r}

encoded_train_data <- predict(dummyVars("~ .", train_default_data,fullRank = T), newdata = train_default_data)
encoded_test_data <- predict(dummyVars("~ .", test_default_data,fullRank = T), newdata = test_default_data)
encoded_test_data<-encoded_test_data[,-1]

predictors <- encoded_train_data[, -1]
response <- as.matrix(encoded_train_data[, 1])

# perform cross-validation with glmnet
cvfit <- cv.glmnet(encoded_train_data[,-1], encoded_train_data[, 1], alpha = 1, nfolds = 10)

# get the 1SE lambda value
lambda_1se <- cvfit$lambda.1se

# fit the final model with the selected lambda value
lasso_fit <- glmnet(predictors, response, alpha = 1, lambda = lambda_1se)

# # extract the coefficients
coefficients <- coef(lasso_fit)
coefficients

lasso_predicted_prob <- predict(lasso_fit, newx= as.matrix(encoded_test_data))
lasso_predicted_loss=lasso_predicted_prob*test_default_data$amount


lasso_test_loss<-test_default_data$default*test_default_data$amount

lasso_MAE<- sum(abs(lasso_test_loss -lasso_predicted_loss)) / nrow(test_default_data)
lasso_MAE
```

Using lasso, 14 coefficients are showing significant and rest all are pushed to zero.
MAE is coming out as 3579



**PCA**

```{r}

scaled_train_data <- scale(encoded_train_data)
scaled_test_data <- scale(encoded_test_data)
scaled_train_data<-scaled_train_data[,-1]

pca <- prcomp(scaled_train_data)
summary(pca)

pca.var <- pca$sdev^2

pve <- pca.var/sum(pca.var)
plot(pve, xlab = "Principal component", 
     ylab = "Proportion of variation explained",
     ylim = c(0, 1), 
     type = 'b')

plot(cumsum(pve), xlab = "Principal component", 
     ylab = "Cumulative Prop. of variation explained",
     ylim = c(0, 1), 
     type = 'b')
#Based on the summary function and the elbow curve, picking top 24 principal components out of 48 that cumulatively explain more than 80 percent of variation

pca_data<-data.frame(Default=encoded_train_data[,'default'],pca$x[,1:24])

# Train a logistic regression model on the transformed data
pca_logit_model <- glm(pca_data$Default ~ ., data = pca_data, family = "binomial")

test.p <- predict(pca, newdata = encoded_test_data[,])

# Make predictions on the testing data
test_pca <- predict(pca_logit_model, newdata=as.data.frame(test.p),type="response")

# Evaluate the performance of the logistic regression model
pca_prediction<-ifelse(test_pca > 0.5, 1,0)

#Below table summarizes the true positives and false positives prediction
table(test_default_data$default, pca_prediction)

pca_predicted_loss=test_pca*test_default_data$amount
pca_test_loss<-test_default_data$default*test_default_data$amount

pca_MAE<- sum(abs(pca_predicted_loss -pca_test_loss)) / nrow(test_default_data)
pca_MAE

```

The mean absolute error is 1344 for variables selected through PCA. 

**PLS**
```{r}
# Fit the PLS model with M chosen by cross-validation
pls_default_fit <- train(as.factor(default)~.,data=encoded_train_data, method = "pls",
                tuneLength = 10, trControl = trainControl(method = "cv", number = 10),
                preProcess = c("center", "scale"))
pls_m <- pls_default_fit$bestTune$ncomp
pls_m
# Fit the final PLS model with the selected M
pls_model <- plsr(default ~ ., data = as.data.frame(encoded_train_data), ncomp = pls_m)
pls_prob <- predict(pls_model, newdata = encoded_test_data)

pls_prediction<-ifelse(pls_prob > 0.5, 1,0)

pls_predicted_loss=pls_prob*test_default_data$amount
pls_test_loss<-test_default_data$default*test_default_data$amount

pls_MAE<- sum(abs(pls_predicted_loss -pls_test_loss)) / nrow(test_default_data)
pls_MAE

```
The loss for PLS is sky rocketing with 41528


**Weighted logistic**
```{r}
sum(train_default_data$default==0)
sum(train_default_data$default==1)

w1=1
w2=50
weight <- ifelse(train_default_data$default==0, 50, 1)


suppressWarnings({weighted_log_model<-glm(default~.,data=train_default_data, family="binomial",weights = weight)
})
summary(weighted_log_model)
testProb <- predict(weighted_log_model, newdata = test_default_data, type = "response")
# Calculate the error on the test data taken out from train
testActual <- ifelse(testProb>0.5, 1, 0)
error <- sum(abs(testActual - test_default_data$default)) / nrow(test_default_data)
error

weighted_train_loss<-test_default_data$default*test_default_data$amount
weightedLoss <- testProb * test_default_data$amount

w_MAE<- sum(abs(weighted_train_loss-weightedLoss)) / nrow(test_default_data)
w_MAE


```

The data is imbalanced with approx 50% more instances of 0 than 1 in the default column. Hence applied weighted logistic regression. I have give weight of 50 to "0" and 1 to "1" in the regression. The error is 0.07 and the MAE is 1226. This is the least MAE.

**Model Selection Steps**
We first started with pre-processing data. Some of the steps involved in pre-processing are:
1. Converting numerical variables to correct format
2. Stripping away characters from 'term' column to make it suitable for use in regression
3. Checking for NAs
4. Replacing NAs with mean value of columns based on the frequency of occurence
5. Converting categorical variables to dummy

Then, we also looked at the scatter plots of all the numerical variables to find if there is a need of variable transformation. All the plots showed random pattern.

The first model I tried is logistic regression as this is a clear classification problem. I divided the training data further into train and test for this method. Then, I calculated the MAE for logistic using the test data from training set as well as the actual test set. The MAE for actual test set is 1929

Then, I moved on to check for lasso regression. There were 14 significant variables and the MAE value was 3579.

The next model I tried is logistic but using Principal component analysis. PCA is a good approach to apply for dimensionality reduction. Since, I didn't find a good number of significant variables through lasso, PCA seemed to be the next best approach. And after fitting PCA and using actual test data, MAE was 1344. 

Although I also tried to fit a PLS model but it performed bad because these are best for continuous variables. PLS assumes a linear relationship between the independent and dependent variables. While this assumption is reasonable for many regression problems, it may not hold for classification problems, where the relationship between the independent and dependent variables may be more complex and nonlinear.

The next model was weighted logistic regression. The data is imbalanced with approx 50% more instances of 0 than 1 in the default column. Hence applied weighted logistic regression. I have give weight of 50 to "0" and 1 to "1" in the regression. The error is 0.07 and the MAE is 1226. This is the least MAE.And hence this is the final model.

This model has the least mean absolute error and is a good fit for this imbalanced datset.


